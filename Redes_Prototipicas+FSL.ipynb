{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Redes Prototipicas y Few shot learning"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import os\n","from torchvision.models import resnet18, ResNet18_Weights\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class PrototypicalNetwork(nn.Module):\n","    def __init__(self):\n","        super(PrototypicalNetwork, self).__init__()\n","        weights = ResNet18_Weights.DEFAULT\n","        self.encoder = resnet18(weights=weights)\n","        self.encoder.fc = nn.Flatten()\n","\n","    def forward(self, x):\n","        return self.encoder(x)\n","\n","def train_episode(model, support_images, support_labels, query_images, query_labels, optimizer):\n","    model.train()\n","    optimizer.zero_grad()\n","    \n","    # Mover al dispositivo adecuado y remover dimensiones innecesarias\n","    support_images = support_images.to(device).squeeze(0)  # Remover la dimensión extra de batch\n","    query_images = query_images.to(device).squeeze(0)\n","    support_labels = support_labels.to(device).squeeze(0)  # Asegúrate de que las etiquetas son 1D\n","    query_labels = query_labels.to(device).squeeze(0)\n","    \n","    # Obtener los embeddings\n","    support_embeddings = model(support_images)\n","    query_embeddings = model(query_images)\n","    \n","    # Calcular prototipos\n","    unique_labels = torch.unique(support_labels)\n","    prototypes = torch.stack([support_embeddings[support_labels == label].mean(0) for label in unique_labels])\n","\n","    # Aquí puedes imprimir los embeddings si es necesario, después de calcular unique_labels\n","    # print(f\"Embeddings de soporte para cada clase: {[support_embeddings[support_labels == label].mean(0) for label in unique_labels]}\")\n","\n","    distances = torch.cdist(query_embeddings, prototypes)\n","    log_p_y = torch.log_softmax(-distances, dim=1)\n","    loss = nn.NLLLoss()(log_p_y, query_labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Calcular accuracy\n","    y_hat = log_p_y.argmax(1)\n","    correct_pred = torch.eq(y_hat, query_labels).sum().item()\n","    total = query_labels.size(0)\n","    accuracy = correct_pred / total\n","\n","    return loss.item(), accuracy\n","\n","\n","\n","\n","def train(model, train_dataset, optimizer, n_way, k_shot, q_query, epochs=20):\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        total_accuracy = 0\n","        for episode in train_loader:\n","            support_images, support_labels, query_images, query_labels = episode\n","\n","            loss, accuracy = train_episode(model, support_images, support_labels, query_images, query_labels, optimizer)\n","            total_loss += loss\n","            total_accuracy += accuracy\n","\n","        avg_loss = total_loss / len(train_loader)\n","        avg_accuracy = total_accuracy / len(train_loader)\n","        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}\")\n","\n","class FewShotDataset(Dataset):\n","    def __init__(self, root_dir, n_way, k_shot, q_query, transform=None):\n","        self.root_dir = root_dir\n","        self.class_folders = os.listdir(root_dir)\n","        self.n_way = n_way\n","        self.k_shot = k_shot\n","        self.q_query = q_query\n","        self.transform = transform\n","        \n","        # Verificar si cada clase tiene suficientes imágenes\n","        for class_name in self.class_folders:\n","            class_dir = os.path.join(self.root_dir, class_name)\n","            image_files = os.listdir(class_dir)\n","            if len(image_files) < (self.k_shot + self.q_query):\n","                raise ValueError(f\"La clase {class_name} no tiene suficientes imágenes. Requiere al menos {self.k_shot + self.q_query} imágenes.\")\n","\n","    def __len__(self):\n","        return 1000  # Este valor puede ajustarse según el número de iteraciones deseadas por época\n","\n","    def __getitem__(self, idx):\n","        # Intentar formar un episodio válido. Si no es posible, levantar una excepción\n","        for attempt in range(10):  # Número de intentos para formar un episodio válido\n","            try:\n","                episode_classes = np.random.choice(self.class_folders, self.n_way, replace=False)\n","                support_images = []\n","                query_images = []\n","                support_labels = []\n","                query_labels = []\n","\n","                for i, class_name in enumerate(episode_classes):\n","                    class_dir = os.path.join(self.root_dir, class_name)\n","                    image_files = os.listdir(class_dir)\n","                    selected_files = np.random.choice(image_files, self.k_shot + self.q_query, replace=False)\n","                    support_files = selected_files[:self.k_shot]\n","                    query_files = selected_files[self.k_shot:]\n","\n","                    for file_name in support_files:\n","                        img_path = os.path.join(class_dir, file_name)\n","                        img = Image.open(img_path).convert('RGB')\n","                        if self.transform:\n","                            img = self.transform(img)\n","                        support_images.append(img)\n","                        support_labels.append(i)\n","\n","                    for file_name in query_files:\n","                        img_path = os.path.join(class_dir, file_name)\n","                        img = Image.open(img_path).convert('RGB')\n","                        if self.transform:\n","                            img = self.transform(img)\n","                        query_images.append(img)\n","                        query_labels.append(i)\n","\n","                # Verificar que cada clase esté representada en el conjunto de soporte y consulta\n","                assert len(set(support_labels)) == self.n_way, \"No todas las clases están representadas en el conjunto de soporte\"\n","                assert len(set(query_labels)) == self.n_way, \"No todas las clases están representadas en el conjunto de consulta\"\n","                \n","                support_images = torch.stack(support_images)\n","                query_images = torch.stack(query_images)\n","                support_labels = torch.tensor(support_labels)\n","                query_labels = torch.tensor(query_labels)\n","\n","                return support_images, support_labels, query_images, query_labels\n","            except ValueError as e:\n","                # Imprimir el error y continuar con el siguiente intento\n","                print(f\"No se pudo formar un episodio válido en el intento {attempt+1}: {e}\")\n","                if attempt == 9:\n","                    raise ValueError(\"No se pudo formar un episodio válido después de varios intentos.\")\n","\n","# Demás código para inicializar y entrenar el modelo...\n","\n","# Configuración del dispositivo\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Instanciación del modelo y optimizador\n","model = PrototypicalNetwork().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Parámetros del entrenamiento\n","n_way = 5\n","k_shot = 5\n","q_query = 15\n","epochs = 12\n","\n","# Ejemplo de transformación\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# Crear el dataset\n","train_dataset = FewShotDataset(root_dir='directorio_datos_train', n_way=n_way, k_shot=k_shot, q_query=q_query, transform=transform)\n","\n","# Comenzar el entrenamiento (asegúrate de ajustar el path del dataset)\n","train(model, train_dataset, optimizer, n_way, k_shot, q_query, epochs)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Matriz de Confusion\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from sklearn.metrics import confusion_matrix\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","\n","# Parámetros del entrenamiento\n","n_way = 5\n","k_shot = 5\n","q_query = 15\n","epochs = 12\n","\n","# Esta función ejecutará el modelo en modo de evaluación y recolectará las predicciones\n","def test_model(model, test_dataset, n_way, k_shot, q_query):\n","    model.eval()  # Poner el modelo en modo de evaluación\n","    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n","    all_preds = []\n","    all_labels = []\n","    \n","    with torch.no_grad():  # No se necesitan gradientes para la evaluación\n","        for episode in test_loader:\n","            support_images, support_labels, query_images, query_labels = episode\n","            support_images = support_images.to(device).squeeze(0)\n","            query_images = query_images.to(device).squeeze(0)\n","            support_labels = support_labels.to(device).squeeze(0)\n","            query_labels = query_labels.to(device).squeeze(0)\n","            \n","            # Obtener los embeddings\n","            support_embeddings = model(support_images)\n","            query_embeddings = model(query_images)\n","            \n","            # Calcular prototipos\n","            unique_labels = torch.unique(support_labels)\n","            prototypes = torch.stack([support_embeddings[support_labels == label].mean(0) for label in unique_labels])\n","\n","            # Calcular distancias y hacer las predicciones\n","            distances = torch.cdist(query_embeddings, prototypes)\n","            log_p_y = torch.log_softmax(-distances, dim=1)\n","            y_hat = log_p_y.argmax(1)\n","            \n","            all_preds.extend(y_hat.cpu().numpy())\n","            all_labels.extend(query_labels.cpu().numpy())\n","\n","    return all_preds, all_labels\n","\n","# Crear el dataset de prueba\n","test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","test_dataset = FewShotDataset(root_dir='directorio_datos_test', n_way=n_way, k_shot=k_shot, q_query=q_query, transform=test_transform)\n","\n","# Ejecutar el modelo en el conjunto de prueba y recolectar predicciones\n","predictions, true_labels = test_model(model, test_dataset, n_way, k_shot, q_query)\n","\n","# Calcular la matriz de confusión\n","conf_matrix = confusion_matrix(true_labels, predictions)\n","print(conf_matrix)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import PIL\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","class_names=['clase_0', 'clase_1', 'clase_2', 'clase_3','clase_4']\n","fig, ax = plt.subplots(figsize=(8, 8))  # Puedes ajustar el tamaño aquí\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.savefig('matriz.jpg')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Guarda el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","# Guardar el modelo\n","def save_model(model, optimizer, epoch, file_path=\"model.pth\"):\n","    # Crear un diccionario con la información que quieres guardar\n","    state = {\n","        'epoch': epoch,\n","        'model_state': model.state_dict(),\n","        'optimizer_state': optimizer.state_dict(),\n","    }\n","    # Guardar el diccionario en el archivo del camino file_path\n","    torch.save(state, file_path)\n","\n","\n","\n","# Ejemplo de cómo guardar el modelo\n","save_model(model, optimizer, epochs, \"prototipicas.pth\")\n","\n","# Ejemplo de cómo cargar el modelo\n","# Nota: Debes crear la instancia de 'model' y 'optimizer' con las mismas características antes de llamar a esta función\n","#epoch = load_model(model, optimizer, \"/mnt/data/my_prototypical_network.pth\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Cargar el modelo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","import torchvision.transforms as transforms\n","from PIL import Image\n","import os\n","from torchvision.models import resnet18, ResNet18_Weights\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class PrototypicalNetwork(nn.Module):\n","    def __init__(self):\n","        super(PrototypicalNetwork, self).__init__()\n","        weights = ResNet18_Weights.DEFAULT\n","        self.encoder = resnet18(weights=weights)\n","        self.encoder.fc = nn.Flatten()\n","\n","    def forward(self, x):\n","        return self.encoder(x)\n","\n","def train_episode(model, support_images, support_labels, query_images, query_labels, optimizer):\n","    model.train()\n","    optimizer.zero_grad()\n","    \n","    # Mover al dispositivo adecuado y remover dimensiones innecesarias\n","    support_images = support_images.to(device).squeeze(0)  # Remover la dimensión extra de batch\n","    query_images = query_images.to(device).squeeze(0)\n","    support_labels = support_labels.to(device).squeeze(0)  # Asegúrate de que las etiquetas son 1D\n","    query_labels = query_labels.to(device).squeeze(0)\n","    \n","    # Obtener los embeddings\n","    support_embeddings = model(support_images)\n","    query_embeddings = model(query_images)\n","    \n","    # Calcular prototipos\n","    unique_labels = torch.unique(support_labels)\n","    prototypes = torch.stack([support_embeddings[support_labels == label].mean(0) for label in unique_labels])\n","\n","    # Aquí puedes imprimir los embeddings si es necesario, después de calcular unique_labels\n","    # print(f\"Embeddings de soporte para cada clase: {[support_embeddings[support_labels == label].mean(0) for label in unique_labels]}\")\n","\n","    distances = torch.cdist(query_embeddings, prototypes)\n","    log_p_y = torch.log_softmax(-distances, dim=1)\n","    loss = nn.NLLLoss()(log_p_y, query_labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Calcular accuracy\n","    y_hat = log_p_y.argmax(1)\n","    correct_pred = torch.eq(y_hat, query_labels).sum().item()\n","    total = query_labels.size(0)\n","    accuracy = correct_pred / total\n","\n","    return loss.item(), accuracy\n","\n","\n","\n","\n","def train(model, train_dataset, optimizer, n_way, k_shot, q_query, epochs=20):\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        total_accuracy = 0\n","        for episode in train_loader:\n","            support_images, support_labels, query_images, query_labels = episode\n","\n","            loss, accuracy = train_episode(model, support_images, support_labels, query_images, query_labels, optimizer)\n","            total_loss += loss\n","            total_accuracy += accuracy\n","\n","        avg_loss = total_loss / len(train_loader)\n","        avg_accuracy = total_accuracy / len(train_loader)\n","        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}\")\n","\n","class FewShotDataset(Dataset):\n","    def __init__(self, root_dir, n_way, k_shot, q_query, transform=None):\n","        self.root_dir = root_dir\n","        self.class_folders = os.listdir(root_dir)\n","        self.n_way = n_way\n","        self.k_shot = k_shot\n","        self.q_query = q_query\n","        self.transform = transform\n","        \n","        # Verificar si cada clase tiene suficientes imágenes\n","        for class_name in self.class_folders:\n","            class_dir = os.path.join(self.root_dir, class_name)\n","            image_files = os.listdir(class_dir)\n","            if len(image_files) < (self.k_shot + self.q_query):\n","                raise ValueError(f\"La clase {class_name} no tiene suficientes imágenes. Requiere al menos {self.k_shot + self.q_query} imágenes.\")\n","\n","    def __len__(self):\n","        return 1000  # Este valor puede ajustarse según el número de iteraciones deseadas por época\n","\n","    def __getitem__(self, idx):\n","        # Intentar formar un episodio válido. Si no es posible, levantar una excepción\n","        for attempt in range(10):  # Número de intentos para formar un episodio válido\n","            try:\n","                episode_classes = np.random.choice(self.class_folders, self.n_way, replace=False)\n","                support_images = []\n","                query_images = []\n","                support_labels = []\n","                query_labels = []\n","\n","                for i, class_name in enumerate(episode_classes):\n","                    class_dir = os.path.join(self.root_dir, class_name)\n","                    image_files = os.listdir(class_dir)\n","                    selected_files = np.random.choice(image_files, self.k_shot + self.q_query, replace=False)\n","                    support_files = selected_files[:self.k_shot]\n","                    query_files = selected_files[self.k_shot:]\n","\n","                    for file_name in support_files:\n","                        img_path = os.path.join(class_dir, file_name)\n","                        img = Image.open(img_path).convert('RGB')\n","                        if self.transform:\n","                            img = self.transform(img)\n","                        support_images.append(img)\n","                        support_labels.append(i)\n","\n","                    for file_name in query_files:\n","                        img_path = os.path.join(class_dir, file_name)\n","                        img = Image.open(img_path).convert('RGB')\n","                        if self.transform:\n","                            img = self.transform(img)\n","                        query_images.append(img)\n","                        query_labels.append(i)\n","\n","                # Verificar que cada clase esté representada en el conjunto de soporte y consulta\n","                assert len(set(support_labels)) == self.n_way, \"No todas las clases están representadas en el conjunto de soporte\"\n","                assert len(set(query_labels)) == self.n_way, \"No todas las clases están representadas en el conjunto de consulta\"\n","                \n","                support_images = torch.stack(support_images)\n","                query_images = torch.stack(query_images)\n","                support_labels = torch.tensor(support_labels)\n","                query_labels = torch.tensor(query_labels)\n","\n","                return support_images, support_labels, query_images, query_labels\n","            except ValueError as e:\n","                # Imprimir el error y continuar con el siguiente intento\n","                print(f\"No se pudo formar un episodio válido en el intento {attempt+1}: {e}\")\n","                if attempt == 9:\n","                    raise ValueError(\"No se pudo formar un episodio válido después de varios intentos.\")\n","\n","# Restaurar el modelo\n","def load_model(model, optimizer, file_path=\"model.pth\"):\n","    # Cargar el estado (si existe)\n","    state = torch.load(file_path, map_location=device)\n","    \n","    # Cargar el estado del modelo y del optimizador desde el archivo\n","    model.load_state_dict(state['model_state'])\n","    optimizer.load_state_dict(state['optimizer_state'])\n","    \n","    return state['epoch']\n","\n","\n","# Configuración del dispositivo\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Instanciación del modelo y optimizador\n","model = PrototypicalNetwork().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Nota: Debes crear la instancia de 'model' y 'optimizer' con las mismas características antes de llamar a esta función\n","epoch = load_model(model, optimizer, \"/kaggle/input/modeloo/prototipicas.pth\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Recall\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.metrics import recall_score\n","\n","# Supongamos que 'true_labels' son tus etiquetas verdaderas y 'predictions' las predicciones de tu modelo\n","recall = recall_score(true_labels, predictions, average=None)  # 'None' calcula el recall para cada clase\n","\n","print(recall)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4556478,"sourceId":7785250,"sourceType":"datasetVersion"},{"datasetId":4567189,"sourceId":7800172,"sourceType":"datasetVersion"},{"datasetId":4579735,"sourceId":7817199,"sourceType":"datasetVersion"},{"datasetId":4592002,"sourceId":7834426,"sourceType":"datasetVersion"},{"datasetId":4594143,"sourceId":7837339,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
