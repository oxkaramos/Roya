{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Entrenamiento del modelo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import os\n","\n","# Asume que las imágenes son de tamaño 299x299 para Xception\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(299),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(299),\n","        transforms.CenterCrop(299),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","data_dir = 'directorio_datos'\n","batch_size = 32\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","               for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import timm\n","import torch\n","\n","model_name = 'xception'  # Asegúrate de que el nombre coincide con los disponibles en timm\n","model = timm.create_model(model_name, pretrained=True, num_classes=5)\n","\n","# Asegúrate de adaptar el resto del código para entrenar, evaluar y usar el modelo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch import optim\n","from torch import nn\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_epochs = 12\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    running_corrects = 0\n","\n","    for inputs, labels in dataloaders['train']:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        _, preds = torch.max(outputs, 1)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","\n","    epoch_loss = running_loss / dataset_sizes['train']\n","    epoch_acc = running_corrects.double() / dataset_sizes['train']\n","\n","    print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Guarda el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'xception_modell.pth')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Matriz de confusion y Recall"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import os\n","from sklearn.metrics import recall_score\n","\n","# Asumiendo que 'model' ya está definido y cargado como se mostró anteriormente\n","\n","# Transformaciones para las imágenes de prueba\n","transform = transforms.Compose([\n","    transforms.Resize(299),\n","    transforms.CenterCrop(299),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# Cargar las imágenes de prueba\n","test_dir = 'directorio_datos_test'\n","test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)\n","class_names = test_dataset.classes\n","\n","# Función para realizar predicciones y calcular la matriz de confusión\n","def predict_and_confusion_matrix(model, dataloader):\n","    y_pred = []\n","    y_true = []\n","    model.eval()  # Establecer el modelo en modo de evaluación\n","    with torch.no_grad():  # No necesitamos calcular gradientes\n","        for inputs, labels in dataloader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            y_pred.extend(preds.cpu().numpy())\n","            y_true.extend(labels.cpu().numpy())\n","    \n","    # Calcular la matriz de confusión\n","    conf_mat = confusion_matrix(y_true, y_pred)\n","    recall = recall_score(y_true, y_pred, average='macro')\n","    return conf_mat,recall\n","\n","# Calcular y mostrar la matriz de confusión\n","conf_mat, recall = predict_and_confusion_matrix(model, test_loader)\n","print(conf_mat)\n","\n","\n","\n","print(f'Recall: {recall}')\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4592541,"sourceId":7835145,"sourceType":"datasetVersion"},{"datasetId":4593778,"sourceId":7836842,"sourceType":"datasetVersion"},{"datasetId":4600561,"sourceId":7846131,"sourceType":"datasetVersion"},{"datasetId":4600963,"sourceId":7846695,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
