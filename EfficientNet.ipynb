{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7834553,"sourceType":"datasetVersion","datasetId":4592105},{"sourceId":7837169,"sourceType":"datasetVersion","datasetId":4594014},{"sourceId":7837300,"sourceType":"datasetVersion","datasetId":4594113},{"sourceId":7853028,"sourceType":"datasetVersion","datasetId":4605693},{"sourceId":7853458,"sourceType":"datasetVersion","datasetId":4605989}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Entrenamiento del modelo","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport os\n\n# Transformaciones para los conjuntos de datos\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ]),\n}\n\n# Asume que 'path_to_train_data' y 'path_to_val_data' son tus rutas de datos\ndata_dir = {'train': 'directorio_datos_entrenamiento', 'val': 'directorio_datos_validacion'}\n\nimage_datasets = {x: datasets.ImageFolder(data_dir[x], data_transforms[x]) for x in ['train', 'val']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\nfrom torch import nn\n\nmodel = timm.create_model('efficientnet_b0', pretrained=True)\nnum_ftrs = model.classifier.in_features\nmodel.classifier = nn.Linear(num_ftrs, 5)\n\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 12  # Ajusta esto según tus necesidades\n\nfor epoch in range(num_epochs):\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()\n        else:\n            model.eval()\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in dataloaders[phase]:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n        \ntorch.save(model.state_dict(), 'efficientnet_modell.pth')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport timm\nfrom torch import nn\n\n# Define el modelo (asegúrate de que sea idéntico al modelo que entrenaste)\nmodel_name = 'efficientnet_b0'  # Asegúrate de usar la misma variante de EfficientNet que usaste para entrenar\nmodel = timm.create_model(model_name, pretrained=False, num_classes=5)\n\n# Cargar los pesos del modelo guardado\nmodel.load_state_dict(torch.load('/kaggle/working/efficientnet_modell.pth'))\n\nmodel.eval()  # Establece el modelo en modo de evaluación\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# Define las transformaciones (deberían ser las mismas que usaste para la validación durante el entrenamiento)\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Cargar el conjunto de datos de validación\ndata_dir = 'directorio_datos'\nvalidation_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'test'), transform=transform)\nvalidation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n\ny_pred = []\ny_true = []\n\n# Desactiva el cálculo de gradientes para ahorrar memoria y acelerar el proceso\nwith torch.no_grad():\n    for inputs, labels in validation_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        y_pred.extend(preds.view(-1).cpu().numpy())\n        y_true.extend(labels.view(-1).cpu().numpy())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Matriz de confusion","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calcular la matriz de confusión\nconf_mat = confusion_matrix(y_true, y_pred)\n\n# Mostrar la matriz de confusión\nfig, ax = plt.subplots(figsize=(5, 4))\nsns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n            xticklabels=validation_dataset.classes, yticklabels=validation_dataset.classes)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.savefig('matriz.jpg')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recall\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.models import resnet18  # Asumiendo que estás usando ResNet18 como ejemplo\nfrom sklearn.metrics import recall_score\nimport numpy as np\n\n# Asegúrate de tener el dispositivo adecuado para PyTorch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Define las transformaciones para tus datos de prueba\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Carga tus datos de prueba\ntest_dataset = datasets.ImageFolder(root='directorio_datos_test', transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Función para cargar el modelo .pth\ndef load_model_pth(model_path, num_classes):\n    model_name = 'efficientnet_b0'  # Asegúrate de usar la misma variante de EfficientNet que usaste para entrenar\n    model = timm.create_model(model_name, pretrained=False, num_classes=5)\n    model.load_state_dict(torch.load('/kaggle/working/efficientnet_modell.pth'))\n    #model = timm.create_model('efficientnet_b0', pretrained=True)\n    #num_ftrs = model.classifier.in_features\n    #model.classifier = nn.Linear(num_ftrs, 5)\n    #model.fc = nn.Linear(model.fc.in_features, num_classes)  # Ajusta según tu modelo\n    model.load_state_dict(torch.load(model_path))\n    model = model.to(device)\n    model.eval()\n    return model\n\n# Carga el modelo .pth\nmodel_path = '/kaggle/working/efficientnet_modell.pth'  # Asume que ya has copiado tu modelo al directorio de trabajo\nmodel = load_model_pth(model_path, num_classes=5)  # Ajusta num_classes según tu caso\n\n# Predicción y cálculo de recall\nall_preds = []\ntrue_classes = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        true_classes.extend(labels.cpu().numpy())\n\n# Calcula el recall\nrecall = recall_score(true_classes, all_preds, average='macro')  # Ajusta el average según tu caso\n\nprint(f'Recall del modelo: {recall}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}