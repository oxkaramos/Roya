{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Entrenamiento del modelo"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T18:11:21.452089Z","iopub.status.busy":"2024-03-02T18:11:21.451537Z","iopub.status.idle":"2024-03-02T18:12:25.108775Z","shell.execute_reply":"2024-03-02T18:12:25.107750Z","shell.execute_reply.started":"2024-03-02T18:11:21.452044Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader\n","import os\n","\n","# Definir transformaciones\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(299),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(299),\n","        transforms.CenterCrop(299),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","data_dir = 'directorio_datos'\n","batch_size = 32\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n","                  for x in ['train', 'val']}\n","dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n","               for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T18:12:26.588311Z","iopub.status.busy":"2024-03-02T18:12:26.587721Z","iopub.status.idle":"2024-03-02T19:03:20.257498Z","shell.execute_reply":"2024-03-02T19:03:20.256335Z","shell.execute_reply.started":"2024-03-02T18:12:26.588278Z"},"trusted":true},"outputs":[],"source":["from torch import nn\n","\n","model = models.inception_v3(pretrained=True)\n","# Ajustar la última capa para 5 clases\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 5)\n","from torch import optim\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","num_epochs = 12\n","\n","for epoch in range(num_epochs):\n","    # Inicializa variables para almacenar resultados tanto de entrenamiento como de validación\n","    print(f'Epoch {epoch+1}/{num_epochs}')\n","    \n","    for phase in ['train', 'val']:\n","        if phase == 'train':\n","            model.train()  # Pone el modelo en modo de entrenamiento\n","        else:\n","            model.eval()   # Pone el modelo en modo de evaluación\n","        \n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        # Itera sobre los datos.\n","        for inputs, labels in dataloaders[phase]:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Solo sigue el historial si está en fase de 'train'\n","            with torch.set_grad_enabled(phase == 'train'):\n","                # Inception v3 devuelve outputs en modo entrenamiento como una tupla\n","                if phase == 'train':\n","                    outputs, aux_outputs = model(inputs)\n","                    loss1 = criterion(outputs, labels)\n","                    loss2 = criterion(aux_outputs, labels)\n","                    loss = loss1 + 0.4*loss2\n","                else:\n","                    outputs = model(inputs)\n","                    loss = criterion(outputs, labels)\n","\n","                _, preds = torch.max(outputs, 1)\n","\n","                # backward + optimize solo si está en fase de 'train'\n","                if phase == 'train':\n","                    loss.backward()\n","                    optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / dataset_sizes[phase]\n","        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","        print(f'{phase} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')"]},{"cell_type":"markdown","metadata":{},"source":["# Guardado del modelo"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T19:13:30.962586Z","iopub.status.busy":"2024-03-02T19:13:30.961776Z","iopub.status.idle":"2024-03-02T19:13:31.284806Z","shell.execute_reply":"2024-03-02T19:13:31.284012Z","shell.execute_reply.started":"2024-03-02T19:13:30.962548Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'inception_v3_model.pth')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Matriz de confusión y recall"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-02T19:14:17.882536Z","iopub.status.busy":"2024-03-02T19:14:17.881777Z","iopub.status.idle":"2024-03-02T19:14:18.471188Z","shell.execute_reply":"2024-03-02T19:14:18.469986Z","shell.execute_reply.started":"2024-03-02T19:14:17.882501Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from sklearn.metrics import confusion_matrix\n","\n","model.eval()\n","\n","# Define las transformaciones\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","# Dispositivo (GPU o CPU)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Ruta al conjunto de datos\n","data_dir = 'directorio_test'\n","\n","# Cargar el conjunto de datos\n","dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n","dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n","class_names = dataset.classes\n","\n","y_pred = []\n","y_true = []\n","\n","# Desactivar el cálculo de gradientes\n","with torch.no_grad():\n","    for images, labels in dataloader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        y_pred.extend(predicted.cpu().numpy())\n","        y_true.extend(labels.cpu().numpy())\n","\n","# Calcular la matriz de confusión\n","confusion_mat = confusion_matrix(y_true, y_pred)\n","recall = recall_score(y_true, y_pred, average='macro') \n","print(confusion_mat)\n","print(f'Recall del modelo: {recall}')\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4522267,"sourceId":7737692,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
