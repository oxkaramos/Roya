{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7843321,"sourceType":"datasetVersion","datasetId":4598493},{"sourceId":7846090,"sourceType":"datasetVersion","datasetId":4600529},{"sourceId":7847111,"sourceType":"datasetVersion","datasetId":4601250}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Entrenamiento del modelo","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Definir transformaciones para los conjuntos de datos\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# Cargar los conjuntos de datos\ndata_dir = 'directorio_datos'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\n# Configurar el modelo\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.resnext50_32x4d(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 5)  # Adaptar a 5 clases\nmodel = model.to(device)\n\n# Definir el criterio de pérdida y el optimizador\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# Aquí añadirías el bucle de entrenamiento y validación\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=12):\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Cada época tiene una fase de entrenamiento y validación\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Establecer el modelo en modo de entrenamiento\n            else:\n                model.eval()   # Establecer el modelo en modo de evaluación\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterar sobre los datos.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Reiniciar los gradientes del optimizador\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Estadísticas\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n    return model\n\n# Entrenar el modelo\nmodel_trained = train_model(model, criterion, optimizer, num_epochs=12)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model_trained.state_dict(), 'model_resnext.pth')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cargar el modelo","metadata":{}},{"cell_type":"code","source":"# Cargar el modelo\nmodel.load_state_dict(torch.load('/kaggle/working/model_resnext.pth'))\nmodel.eval()  # Establecer en modo de evaluación\n\n# Aquí debes cargar tus imágenes de prueba, aplicar las transformaciones necesarias y pasarlas al modelo\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Matriz de confusion y Recall","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import confusion_matrix, recall_score\nimport numpy as np\nimport os\n\n# Asumiendo que 'model' ya está definido y cargado como se mostró anteriormente\n\n# Transformaciones para las imágenes de prueba\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Cargar las imágenes de prueba\ntest_dir = 'directorio_datos_test'\ntest_dataset = datasets.ImageFolder(test_dir, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)\nclass_names = test_dataset.classes\n\n# Función para realizar predicciones y calcular la matriz de confusión\ndef predict_and_confusion_matrix(model, dataloader):\n    y_pred = []\n    y_true = []\n    model.eval()  # Establecer el modelo en modo de evaluación\n    with torch.no_grad():  # No necesitamos calcular gradientes\n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            y_pred.extend(preds.cpu().numpy())\n            y_true.extend(labels.cpu().numpy())\n    \n    # Calcular la matriz de confusión\n    conf_mat = confusion_matrix(y_true, y_pred)\n    recall = recall_score(y_true, y_pred, average='macro')\n    return conf_mat, recall\n\n# Calcular y mostrar la matriz de confusión\nconf_mat, recall = predict_and_confusion_matrix(model, test_loader)\nprint(conf_mat)\nprint(f'Recall: {recall}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}